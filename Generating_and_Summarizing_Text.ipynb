{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20144d35",
   "metadata": {},
   "source": [
    "## Little about transformers and hugging face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee844d",
   "metadata": {},
   "source": [
    "###  The Transformer in NLP is a novel architecture that aims to solve sequence-to-sequence tasks.  Transformers are semi-supervised machine learning models that are primarily used with text data and  have replaced recurrent neural networks in natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3683fa",
   "metadata": {},
   "source": [
    "### The Hugging Face transformers package is an immensely popular Python library providing pretrained models that  are extraordinarily useful for a variety of natural language processing (NLP) tasks. It previously supported only PyTorch, but, as of late 2019, TensorFlow 2 is supported as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903babb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\appdata\\roaming\\python\\python38\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "# install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18206809",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06369641",
   "metadata": {},
   "source": [
    "#### import model (GPT2LMHeadModel) to generate text form pretrained model \n",
    "#### and tokenizer (GPT2Tokenizer) to encode and decode\n",
    "#### using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1889f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df7c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it is the first time it will download for you the pretrained model  \n",
    "# we can use also use the small version just by replacing  gpt2-large by gpt2\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1aeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it is the first time it will download for you the pretrained model  \n",
    "# we can use also the small version just by replacing  gpt2-large by gpt2\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553ea129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model will generate text for you based on this sentence \n",
    "\n",
    "sentence = 'Natural language processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4f1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the sentence to tokens\n",
    "\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7c7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded sentence : tensor([35364,  3303,  7587]) \n",
      " normale sentence : Natural language processing\n"
     ]
    }
   ],
   "source": [
    "# display the input_ids\n",
    "\n",
    "print('encoded sentence :',input_ids[0],'\\n','normale sentence :',tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3afd941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text until the output length reaches 300 word\n",
    "\n",
    "output = model.generate(input_ids, max_length=300, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8752088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35364,  3303,  7587,   357,    43, 22182,     8,   318,   257,  8173,\n",
       "           326,  3578,  9061,   284,  1833,   262,  3616,   286,  3288,  3303,\n",
       "            13,   406, 22182,   318,  1912,   319,   262,  2126,   326,   262,\n",
       "          1692,  3632,   318,  6007,   286,  7587,   257,  1588,  2033,   286,\n",
       "          1321,   287,   257,  1790,  2278,   286,   640,    11,   290,   326,\n",
       "           428,  1321,   460,   788,   307,   973,   284,   787,  1167,  4972,\n",
       "           546,   262,   995,  1088,   514,    13,   198,   198,  1890,  1672,\n",
       "            11,   257,  3644,  1244,   307,  1498,   284, 13249,   326,   257,\n",
       "          1048,   318,  7954,   416,  2045,   379,   511, 16324, 14700,    11,\n",
       "           393,   326,   484,   389,   287,  2356,   416, 22712,   511,  1767,\n",
       "          8650,    13,   317,  3644,   460,   635,   307,  8776,   284,  7564,\n",
       "          1728,  2456,   290, 20144,    11,   884,   355,   366,    40,  1842,\n",
       "           345,     1,   393,   366,  1026,   338,   257,  4950,  1110,   287,\n",
       "           968,  1971,  2254,   526,   770,  2099,   286,  4572,  4673,   460,\n",
       "           307,  5625,   284,   257,  3094,  4996,   286,  8861,    11,  1390,\n",
       "          2939,  9465,    11,  4046,  9465,   290,  2420,  7587,    13, 50256]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output variable has now an encoded text result\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1256878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (LNP) is a technique that allows computers to understand the meaning of natural language. LNP is based on the idea that the human brain is capable of processing a large amount of information in a short period of time, and that this information can then be used to make inferences about the world around us.\n",
      "\n",
      "For example, a computer might be able to infer that a person is angry by looking at their facial expressions, or that they are in pain by analyzing their body movements. A computer can also be trained to recognize certain words and phrases, such as \"I love you\" or \"It's a beautiful day in New York City.\" This type of machine learning can be applied to a wide variety of tasks, including image recognition, speech recognition and text processing.\n"
     ]
    }
   ],
   "source": [
    "# decode the output\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5281ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the text in txt file and save it to the actuall directory\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "with open('blog.txt' , 'w') as f: \n",
    "    f.write(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825c0daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (LNP) is a technique that allows computers to understand the meaning of natural language. LNP is based on the idea that the human brain is capable of processing a large amount of information in a short period of time, and that this information can then be used to make inferences about the world around us.\n",
      "\n",
      "For example, a computer might be able to infer that a person is angry by looking at their facial expressions, or that they are in pain by analyzing their body movements. A computer can also be trained to recognize certain words and phrases, such as \"I love you\" or \"It's a beautiful day in New York City.\" This type of machine learning can be applied to a wide variety of tasks, including image recognition, speech recognition and text processing.\n"
     ]
    }
   ],
   "source": [
    "# read the saved file to check content\n",
    "\n",
    "f = open(\"blog.txt\", \"r\")\n",
    "print(f.read()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a23fc",
   "metadata": {},
   "source": [
    "### Summariziation  , Sentiment analysis , Question answer  \n",
    "### there are other models that we can use them :  audio-classification,  automatic-speech-recognition,  feature-extraction,  text-classification,  token- classification,   question-answering,   table-question-answering', fill-mask,      summarization,  translation,  text2text-generation,   text-generation,  zero-shot-classification,  conversational,    image-classification,  image-segmentation,   object-detection,  translation_XX_to_YY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18eb6ee",
   "metadata": {},
   "source": [
    "### Summariziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e1efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use pipeline for easily downloading and use the summarization\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38d19639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "# use summarization \n",
    "\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111e7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the text that will be summarized\n",
    "\n",
    "Blog = ''' \n",
    "NLP tasks :\n",
    "Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines \n",
    "the intended meaning of text or voice data. \n",
    "Homonyms, homophones, sarcasm, idioms, metaphors, grammar and usage exceptions, \n",
    "variations in sentence structure—these just a few of the irregularities of human language that take humans years to learn,\n",
    "but that programmers must teach natural language-driven applications to recognize and understand accurately from the start,\n",
    "if those applications are going to be useful.\n",
    "Several NLP tasks break down human text and voice data in ways that help the computer make sense of what it's ingesting.\n",
    "Some of these tasks include the following:\n",
    "\n",
    "    Speech recognition, also called speech-to-text, is the task of reliably converting voice data into text data.\n",
    "    Speech recognition is required for any application that follows voice commands or answers spoken questions.\n",
    "    What makes speech recognition especially challenging is the way people talk—quickly, slurring words together, \n",
    "    with varying emphasis and intonation, in different accents, and often using incorrect grammar.\n",
    "    Part of speech tagging, also called grammatical tagging, is the process of determining \n",
    "    the part of speech of a particular word or piece of text based on its use and context. \n",
    "    Part of speech identifies ‘make’ as a verb in ‘I can make a paper plane,’ and as a noun in ‘What make of car do you own?’\n",
    "    Word sense disambiguation is the selection of the meaning of a word with multiple meanings  through a process \n",
    "    of semantic analysis that determine the word that makes the most sense in the given context. For example, \n",
    "    word sense disambiguation helps distinguish the meaning of the verb 'make' in ‘make the grade’ (achieve) vs.\n",
    "    ‘make a bet’ (place).\n",
    "    Named entity recognition, or NEM, identifies words or phrases as useful entities.\n",
    "    NEM identifies ‘Kentucky’ as a location or ‘Fred’ as a man's name.\n",
    "    Co-reference resolution is the task of identifying if and when two words refer to the same entity.\n",
    "    The most common example is determining the person or object to which a certain pronoun refers (e.g., ‘she’ = ‘Mary’), \n",
    "    but it can also involve identifying a metaphor or an idiom in the text \n",
    "    (e.g., an instance in which 'bear' isn't an animal but a large hairy person).\n",
    "    Sentiment analysis attempts to extract subjective qualities—attitudes, emotions, sarcasm, confusion, suspicion—from text.\n",
    "    Natural language generation is sometimes described as the opposite of speech recognition or speech-to-text; \n",
    "    it's the task of putting structured information into human language. \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f74ce1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines the intended meaning of text or voice data . NLP tasks break down human text and voice data in ways that help the computer make sense of what it's ingesting .\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the text with result between 30 and 90 word \n",
    "\n",
    "summarizer(Blog, max_length=90, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21140a7",
   "metadata": {},
   "source": [
    "### Sentiment  Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68909334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "# use  sentiment-analysis classifier if it is the first time it will download the model for you \n",
    "\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70989ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# the sentence to classifiy it can contain more than one sentence \n",
    "\n",
    "sentences_to_class= classifier(['i am happy','i am not happy','i am sorry but i am happy.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6865adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998801946640015}, {'label': 'NEGATIVE', 'score': 0.9997896552085876}, {'label': 'POSITIVE', 'score': 0.999850869178772}]\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "\n",
    "print(sentences_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c725861",
   "metadata": {},
   "source": [
    "### Question  Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c74076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    }
   ],
   "source": [
    "# import tokenizer and model for question-answer\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ac4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use this text to extract answer for the choosing question\n",
    "# so the model will take the question and will search the answer in the text provided\n",
    "\n",
    "text = r\"\"\"\n",
    " Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) for Natural Language Understanding (NLU) and Natural\n",
    "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "TensorFlow 2.0 and PyTorch.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"How many pretrained models are available in Transformers?\",\n",
    "    \"What does Transformers provide?\",\n",
    "    \"Transformers provides interoperability between which frameworks?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba0e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5269609689712524, 'start': 255, 'end': 263, 'answer': 'over 32+'}\n",
      "{'score': 0.9512110948562622, 'start': 93, 'end': 122, 'answer': 'general-purpose\\narchitectures'}\n",
      "{'score': 0.8400999307632446, 'start': 334, 'end': 360, 'answer': 'TensorFlow 2.0 and PyTorch'}\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    print(model(question,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97318dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94eabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b83f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95726bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
